# Word Count using PySpark

This project implements a word count application using Apache Spark in Python. It covers both basic and extended word counting capabilities while applying common preprocessing steps like punctuation removal, case normalization, and stopword filtering.

---

## Project Objective

The objective of this assignment is to:

- Develop a Spark application that performs word count on one or more text files.
- Preprocess text by:
  - Converting to lowercase
  - Removing punctuation
  - Ignoring stopwords
- Generate a frequency count of each word.
- Sort the words by frequency in descending order.
- Extend the functionality to support multiple input files.

---

##  Technologies Used

- Python
- Apache Spark (PySpark)
- Google Colab / Jupyter Notebook
- Basic text preprocessing (NLP)

---

##  How to Run the Project

1. **Clone the Repository**
   ```bash
   git clone https://github.com/your-username/pyspark-wordcount-assignment.git
   cd pyspark-wordcount-assignment
